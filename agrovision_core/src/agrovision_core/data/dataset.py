"""
PyTorch Dataset for AgroVision crop classification.

This module provides a fast-loading Dataset class that reads from
pre-processed .npy files generated by prepare_dataset.py.

Usage:
    from backend.src.data.dataset import CropDataset, get_dataloaders

    # Load dataset
    train_dataset = CropDataset("data/processed", split="train")
    val_dataset = CropDataset("data/processed", split="val")

    # Or use the convenience function
    train_loader, val_loader = get_dataloaders("data/processed", batch_size=32)
"""

import json
from pathlib import Path
from typing import Callable, Optional, Union

import numpy as np
import torch
from torch.utils.data import DataLoader, Dataset


class CropDataset(Dataset):
    """
    PyTorch Dataset for crop classification from .npy files.

    Attributes
    ----------
    images : np.ndarray
        Array of shape (N, 12, 256, 256) containing normalized satellite imagery
    masks : np.ndarray
        Array of shape (N, 256, 256) containing crop class labels
    transforms : callable, optional
        Optional transforms to apply to (image, mask) pairs
    class_map : dict
        Mapping of class IDs to class names and colors
    """

    def __init__(
        self,
        data_dir: Union[str, Path],
        split: str = "train",
        transforms: Optional[Callable] = None,
        load_to_memory: bool = True,
    ):
        """
        Initialize the CropDataset.

        Parameters
        ----------
        data_dir : str or Path
            Path to the processed data directory containing .npy files
        split : str
            Which split to load: 'train' or 'val'
        transforms : callable, optional
            Optional transforms to apply to each sample
        load_to_memory : bool
            If True, load entire dataset to memory for faster access.
            If False, use memory-mapped arrays (slower but lower memory).
        """
        self.data_dir = Path(data_dir)
        self.split = split
        self.transforms = transforms

        # Load arrays
        images_path = self.data_dir / f"{split}_images.npy"
        masks_path = self.data_dir / f"{split}_masks.npy"

        if not images_path.exists():
            raise FileNotFoundError(
                f"Images file not found: {images_path}\n"
                "Run prepare_dataset.py first to generate the data."
            )

        if load_to_memory:
            self.images = np.load(images_path)
            self.masks = np.load(masks_path)
        else:
            # Memory-mapped mode for large datasets
            self.images = np.load(images_path, mmap_mode="r")
            self.masks = np.load(masks_path, mmap_mode="r")

        # Load class map
        class_map_path = self.data_dir / "class_map.json"
        if class_map_path.exists():
            with open(class_map_path, encoding="utf-8") as f:
                self.class_map = json.load(f)
        else:
            self.class_map = {}

        # Build convenient mappings between raw class ids and contiguous training indices:
        # - raw_to_contig: raw_id -> contiguous idx (0..N-1)
        # - index_to_raw: contiguous idx -> raw_id
        classes = self.class_map.get("classes", {})
        if classes:
            raw_ids = sorted(int(k) for k in classes.keys())
            self.raw_to_contig = {raw_id: i for i, raw_id in enumerate(raw_ids)}
            self.index_to_raw = {i: raw_id for i, raw_id in enumerate(raw_ids)}
        else:
            self.raw_to_contig = {}
            self.index_to_raw = {}

        # Load normalization stats
        stats_path = self.data_dir / "normalization_stats.json"
        if stats_path.exists():
            with open(stats_path, encoding="utf-8") as f:
                self.norm_stats = json.load(f)
        else:
            self.norm_stats = {}

    def __len__(self) -> int:
        """Return the number of samples in the dataset."""
        return len(self.images)

    def __getitem__(self, idx: int) -> dict:
        """
        Get a single sample.

        Parameters
        ----------
        idx : int
            Sample index

        Returns
        -------
        dict
            Dictionary containing:
            - 'image': torch.Tensor of shape (12, 256, 256), float32
            - 'mask': torch.Tensor of shape (256, 256), int64
        """
        image = self.images[idx].copy()  # (12, 256, 256)
        mask = self.masks[idx].copy()  # (256, 256)

        if self.transforms is not None:
            image, mask = self.transforms(image, mask)

        return {
            "image": torch.from_numpy(image).float(),
            "mask": torch.from_numpy(mask).long(),
        }

    @property
    def num_classes(self) -> int:
        """Return the number of classes."""
        if self.class_map:
            if "num_classes" in self.class_map:
                return int(self.class_map.get("num_classes", 14))
            # Fallback to computed mapping length
            return len(self.index_to_raw) if self.index_to_raw else 14
        return 14

    @property
    def num_channels(self) -> int:
        """Return the number of input channels (bands)."""
        return self.images.shape[1]

    def get_class_weights(self, normalize: bool = True) -> torch.Tensor:
        """
        Compute class weights for contiguous class IDs (0..num_classes-1).
        Assumes masks are already remapped to contiguous labels by prepare_dataset.py.
        """
        num_classes = self.num_classes

        # Get counts (should already be contiguous after Fix 1)
        class_counts = self.class_map.get("class_counts", None)
        if class_counts is None:
            unique, counts = np.unique(self.masks, return_counts=True)
            class_counts = {int(k): int(v) for k, v in zip(unique, counts)}
        else:
            # JSON keys may be strings
            class_counts = {int(k): int(v) for k, v in class_counts.items()}

        total_pixels = sum(class_counts.values())

        weights = np.zeros(num_classes, dtype=np.float32)
        for cls_id in range(num_classes):
            count = class_counts.get(cls_id, 1)
            weights[cls_id] = total_pixels / (num_classes * count)

        if normalize:
            weights = weights / weights.sum() * num_classes

        return torch.from_numpy(weights)


    def get_class_names(self) -> dict[int, str]:
        """Return mapping of class ID to class name."""
        if "classes" in self.class_map:
            return {
                int(k): v["name"] for k, v in self.class_map["classes"].items()
            }
        return {}

    def get_class_colors(self) -> dict[int, list[int]]:
        """Return mapping of class ID to RGB color."""
        if "classes" in self.class_map:
            return {
                int(k): v["color"] for k, v in self.class_map["classes"].items()
            }
        return {}


def get_dataloaders(
    data_dir: Union[str, Path],
    batch_size: int = 32,
    num_workers: int = 4,
    transforms: Optional[Callable] = None,
    pin_memory: bool = True,
) -> tuple[DataLoader, DataLoader]:
    """
    Create training and validation DataLoaders.

    Parameters
    ----------
    data_dir : str or Path
        Path to processed data directory
    batch_size : int
        Batch size for training and validation
    num_workers : int
        Number of data loading workers
    transforms : callable, optional
        Transforms to apply to samples
    pin_memory : bool
        Pin memory for faster GPU transfer

    Returns
    -------
    tuple[DataLoader, DataLoader]
        (train_loader, val_loader)
    """
    train_dataset = CropDataset(data_dir, split="train", transforms=transforms)
    val_dataset = CropDataset(data_dir, split="val", transforms=transforms)

    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=pin_memory,
        drop_last=True,
    )

    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=pin_memory,
        drop_last=False,
    )

    return train_loader, val_loader


class RandomFlipRotate:
    """
    Random horizontal/vertical flip and 90-degree rotation augmentation.

    Applies the same transform to both image and mask.
    """

    def __init__(self, p_flip: float = 0.5, p_rotate: float = 0.5):
        """
        Parameters
        ----------
        p_flip : float
            Probability of horizontal/vertical flip
        p_rotate : float
            Probability of 90-degree rotation
        """
        self.p_flip = p_flip
        self.p_rotate = p_rotate

    def __call__(
        self, image: np.ndarray, mask: np.ndarray
    ) -> tuple[np.ndarray, np.ndarray]:
        """Apply random transforms to image and mask."""
        # Random horizontal flip
        if np.random.random() < self.p_flip:
            image = np.flip(image, axis=2).copy()  # Flip width (axis 2 for CHW)
            mask = np.flip(mask, axis=1).copy()  # Flip width (axis 1 for HW)

        # Random vertical flip
        if np.random.random() < self.p_flip:
            image = np.flip(image, axis=1).copy()  # Flip height
            mask = np.flip(mask, axis=0).copy()

        # Random 90-degree rotation
        if np.random.random() < self.p_rotate:
            k = np.random.randint(1, 4)  # 1, 2, or 3 rotations
            image = np.rot90(image, k, axes=(1, 2)).copy()
            mask = np.rot90(mask, k, axes=(0, 1)).copy()

        return image, mask
