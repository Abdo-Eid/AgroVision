# U-Net Training Guide for AgroVision

**For:** Student B/C (Model Implementation & Training)
**Prepared By:** Student A (Data Pipeline)
**Date:** December 2024

---

## 1. What You're Building

A **semantic segmentation model** that takes satellite imagery and outputs a per-pixel crop classification map.

```
INPUT                           OUTPUT
┌─────────────────┐            ┌──────────────────────┐
│ Satellite Image │            │ Segmentation Mask    │
│ 12 bands        │  ──U-Net──►│ per-pixel class IDs  │
│ 256×256 pixels  │            │ (incl. unlabeled=0)  │
└─────────────────┘            └──────────────────────┘
     (12, 256, 256)                  (256, 256)
```

---

## 2. What Processing Was Done (Data Pipeline Summary)

### 2.1 Raw Data Source

**AgriFieldNet Competition Dataset** from Radiant MLHub:

* **Location:** Uttar Pradesh & Rajasthan, India
* **Satellite:** Sentinel-2 (ESA)
* **Time:** Single timestamp per tile (cloud-free composite)
* **Original format:** GeoTIFF files organized by tile ID

### 2.2 Band Extraction & Stacking

All **12 Sentinel-2 spectral bands** were extracted and stacked in this order:

| Index | Band | Wavelength | What It Captures                             |
| ----- | ---- | ---------- | -------------------------------------------- |
| 0     | B01  | 443 nm     | Coastal/Aerosol (atmospheric correction)     |
| 1     | B02  | 490 nm     | **Blue** (visible)                           |
| 2     | B03  | 560 nm     | **Green** (visible)                          |
| 3     | B04  | 665 nm     | **Red** (visible, chlorophyll absorption)    |
| 4     | B05  | 705 nm     | Red Edge 1 (vegetation stress)               |
| 5     | B06  | 740 nm     | Red Edge 2 (canopy structure)                |
| 6     | B07  | 783 nm     | Red Edge 3 (leaf area index)                 |
| 7     | B08  | 842 nm     | **NIR** (vegetation health, NDVI)            |
| 8     | B8A  | 865 nm     | NIR Narrow (fine vegetation detail)          |
| 9     | B09  | 945 nm     | Water Vapor                                  |
| 10    | B11  | 1610 nm    | **SWIR 1** (soil moisture, crop water)       |
| 11    | B12  | 2190 nm    | **SWIR 2** (mineral content, drought stress) |

### 2.3 Spatial Resampling

All bands resampled to **256×256 pixels** using:

* **Bilinear interpolation** for spectral data
* **Nearest-neighbor** for labels

### 2.4 Normalization (Z-Score)

Each band normalized independently using training-set stats:

```
normalized_pixel = (raw_pixel - band_mean) / (band_std + 1e-6)
```

### 2.5 Train/Validation Split

| Split      | Tiles | Percentage |
| ---------- | ----- | ---------- |
| Training   | 932   | 80%        |
| Validation | 233   | 20%        |

---

## 3. What the U-Net Will Learn (Correct Label Semantics)

### 3.1 The Classification Task

The model learns to predict **crop class at each labeled pixel**.

### ✅ Critical Label Rule (Fix)

**Class `0` is NOT a real class.**
It means **unlabeled / background / ignore** and must be excluded from supervision.

So the training setup is:

* `0` = unlabeled / background (**ignore**)
* `1..K` = real crop classes (**learn these**)

> The model can see background pixels in the input image, but they must not contribute to the loss.

### 3.2 Class List (Reality Check)

Your masks contain IDs like `0, 1, 2, 4, 9, 13, 36, ...` (not contiguous).
So you must do **one** of these:

**Option A (recommended): Remap labels to contiguous IDs**

* Keep `0` as ignore
* Map the “real classes” to `1..K` contiguously

**Option B: Use NUM_CLASSES large enough to include max ID (wasteful)**

* Example: if max label is 36, you’d need `NUM_CLASSES = 37`
* Not ideal

(Everything below assumes you did Option A, i.e. real classes are `1..K`.)

---

## 4. The Critical Mistake (What Went Wrong)

### ❌ Mistake: Training “background/unlabeled” as a real class (class 0)

Because class `0` is ~99% of pixels, the model finds a trivial solution:

> “Predict 0 everywhere.”

This yields high pixel accuracy but **zero useful learning** for crops.

### Why Class Weights Don’t Fully Save This

Even with class weights, you are still *supervising* the model to learn “0”.
Since the dataset is dominated by unlabeled pixels, the gradients are still heavily driven by “predict 0”, and the model collapses.

✅ **Correct fix:** treat 0 as *ignore*, not a class.

---

## 5. Correct Training Setup (Ignore Unlabeled Pixels)

### 5.1 Dataset Returns Mask Unchanged

❗ Do NOT delete or filter background inside the dataset.

```python
return {
    "image": image,   # [C, H, W]
    "mask": mask      # [H, W] values: 0(ignore), 1..K(real)
}
```

### 5.2 Model Output Still Includes Index 0

```python
IGNORE_INDEX = 0
NUM_CLASSES = K + 1  # include channel 0 even though it's ignored

logits = model(images)  # [B, NUM_CLASSES, H, W]
```

### 5.3 Loss Function (Key Fix)

```python
criterion = torch.nn.CrossEntropyLoss(ignore_index=IGNORE_INDEX)
loss = criterion(logits, masks)
```

**Effect:**

* Pixels with mask value `0` contribute **nothing**
* They do **not** affect gradients

---

## 6. Minimal Training Loop

```python
for batch in loader:
    images = batch["image"].to(device)
    masks  = batch["mask"].to(device)

    optimizer.zero_grad()
    logits = model(images)
    loss = criterion(logits, masks)
    loss.backward()
    optimizer.step()
```

---

## 7. Recommended: Skip Mostly-Unlabeled Tiles

```python
valid_pixels = (masks != IGNORE_INDEX).sum()
if valid_pixels < 0.05 * masks.numel():
    continue
```

This prevents wasting batches where almost nothing is labeled.

---

## 8. Metrics (Also Must Ignore Unlabeled)

When computing IoU/F1/mIoU:

* exclude pixels where `mask == 0`
* otherwise metrics will be dominated by unlabeled background

---

## Summary (Updated)

| Aspect                  | Correct Setup                                       |
| ----------------------- | --------------------------------------------------- |
| **Mask meaning**        | `0` = unlabeled/ignore, `1..K` = crops              |
| **Main challenge**      | Most pixels are unlabeled (not “background class”)  |
| **Critical fix**        | `CrossEntropyLoss(ignore_index=0)`                  |
| **Common failure mode** | Treating 0 as a real class → “predict 0 everywhere” |

**Mental model:**

> The model learns only from labeled pixels. Unlabeled pixels provide context, not supervision.
