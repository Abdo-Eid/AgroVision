# AgroVision

**AgroVision Crop Mapper** is a user-friendly, map-based application for crop mapping using **semantic segmentation and deep learning**.
The system follows a **modern web architecture** with a **React (shadcn) frontend** and a **FastAPI backend**, enabling non-technical users to explore, analyze, and export crop maps while keeping the machine learning pipeline modular, reproducible, and scalable.

---

### ğŸ›°ï¸ What AgriFieldNet actually contains

* **256Ã—256 Sentinel-2 image chips**

* **12 spectral bands** per chip

* For each chip:

  * **Satellite imagery** (multiband TIFFs)
  * **Raster label file** (crop IDs)
  * **Field ID file** (field-level reference)

* The dataset is **already tiled**, so no manual mosaicking or tiling is required.

---

### ğŸ“‚ What this means for your project

**â†’ No fundamental change to the ML pipeline is required.**
However, the project structure is clarified to:

* separate **shared ML code**, **backend API**, and **frontend UI**
* support parallel work
* align with real-world deployment practices
* make notebooks reusable **without** `sys.path` hacks by installing shared code as a package

---

## 1) Simplified file structure (clean + easy to split)

> **Key update:** shared ML code is now a proper Python library: `agrovision_core/`
> The backend imports from it, and notebooks can import it directly.

```
agrovision-crop-mapper/
â”‚
â”œâ”€ README.md
â”œâ”€ .gitignore
â”‚
â”œâ”€ config/
â”‚   â””â”€ config.yaml                 # paths, device, tile_limit, class names/colors, band list
â”‚
â”œâ”€ data/                           # local data (NOT pushed)
â”‚   â”œâ”€ raw/                        # downloaded AgriFieldNet (untouched)
â”‚   â”‚   â”œâ”€ source/
â”‚   â”‚   â”œâ”€ train_labels/
â”‚   â”‚   â””â”€ test_labels/
â”‚   â”‚
â”‚   â”œâ”€ processed/                  # PyTorch-ready (generated once)
â”‚   â”‚   â”œâ”€ train_images.npy         # (N, C, H, W)
â”‚   â”‚   â”œâ”€ train_masks.npy          # (N, H, W)
â”‚   â”‚   â”œâ”€ val_images.npy
â”‚   â”‚   â”œâ”€ val_masks.npy
â”‚   â”‚   â””â”€ class_map.json
â”‚   â”‚
â”‚   â””â”€ splits/
â”‚       â”œâ”€ train_ids.csv
â”‚       â””â”€ val_ids.csv
â”‚
â”œâ”€ agrovision_core/                # âœ… shared ML library (installable package)
â”‚   â”œâ”€ pyproject.toml
â”‚   â”œâ”€ README.md
â”‚   â””â”€ src/
â”‚      â””â”€ agrovision_core/
â”‚         â”œâ”€ data/                 # dataset + preprocessing
â”‚         â”‚  â”œâ”€ download_links.md
â”‚         â”‚  â”œâ”€ prepare_dataset.py
â”‚         â”‚  â””â”€ dataset.py
â”‚         â”‚
â”‚         â”œâ”€ models/               # segmentation models (from scratch)
â”‚         â”‚  â”œâ”€ blocks.py          # CNN + transformer blocks
â”‚         â”‚  â”œâ”€ unet_baseline.py
â”‚         â”‚  â””â”€ unet_transformer.py
â”‚         â”‚
â”‚         â”œâ”€ train/                # offline training + evaluation
â”‚         â”‚  â”œâ”€ train.py
â”‚         â”‚  â”œâ”€ evaluate.py
â”‚         â”‚  â””â”€ metrics.py
â”‚         â”‚
â”‚         â””â”€ utils/
â”‚            â”œâ”€ io.py
â”‚            â”œâ”€ viz.py
â”‚            â””â”€ logging.py
â”‚
â”œâ”€ backend/                        # FastAPI backend (Python)
â”‚   â”œâ”€ main.py                     # FastAPI entry point
â”‚   â”œâ”€ api/
â”‚   â”‚   â”œâ”€ routes.py               # REST endpoints (/infer, /stats, /export)
â”‚   â”‚   â””â”€ schemas.py              # Pydantic request/response models
â”‚   â”œâ”€ services/
â”‚   â”‚   â””â”€ inference_service.py    # connects API to ML inference (imports agrovision_core)
â”‚   â””â”€ src/                        # optional backend-only modules (NOT shared ML)
â”‚       â””â”€ __init__.py
â”‚
â”œâ”€ notebooks/                      # Jupyter notebooks for exploration and testing
â”‚
â”œâ”€ frontend/                       # React + shadcn UI
â”‚   â”œâ”€ package.json
â”‚   â”œâ”€ src/
â”‚   â”‚   â”œâ”€ main.tsx
â”‚   â”‚   â”œâ”€ app/                    # pages / routes
â”‚   â”‚   â”œâ”€ components/             # shadcn + custom components
â”‚   â”‚   â””â”€ lib/api.ts              # API calls to FastAPI
â”‚   â””â”€ ...
â”‚
â”œâ”€ outputs/                        # generated outputs (NOT pushed)
â”‚   â”œâ”€ runs/                       # model checkpoints, logs
â”‚   â””â”€ exports/                    # PNG / CSV generated by backend
â”‚
â””â”€ tests/
   â””â”€ test_smoke.py
```

frontend **never touches ML code directly**.

---

## Shared ML library (agrovision_core)

### Why we introduced `agrovision_core/`

Before, shared code lived under `backend/src/...`, which made notebooks painful because imports depended on where code was executed from.

Now, shared ML code is a **real Python package**, so:

* notebooks can import it directly (no path hacks)
* backend can import it cleanly
* training/evaluation can be run from anywhere

### How it is installed (uv)

From the repo root:

```bash
uv add --editable ./agrovision_core
```

Editable install means changes in `agrovision_core/src/agrovision_core/...` apply immediately.

### Quick verification

```bash
uv run python -c "import agrovision_core; print('OK:', agrovision_core.__file__)"
```

---

## Notebook clarification (brief)

Keep notebooks as **orchestrators** only. Put all logic in `agrovision_core/` and reuse it.

Assume your notebook lives at `notebooks/exploration.ipynb`.

âœ… **No `sys.path.append(...)` required** (because `agrovision_core` is installed editable via uv).

Import directly:

```python
from agrovision_core.train.train import train
from agrovision_core.train.evaluate import evaluate
from agrovision_core.data.dataset import CropDataset
from agrovision_core.models.unet_baseline import UNet
from agrovision_core.utils.io import load_config
```

Load config once and never redefine paths/classes/devices in the notebook:

```python
cfg = load_config("config/config.yaml")
```

Run training and evaluation from the notebook:

```python
model, train_metrics = train(cfg)
eval_results = evaluate(model, cfg)
```

**Architecture split (same code used everywhere):**

```
Training logic  -> agrovision_core/src/agrovision_core/train/
Model code      -> agrovision_core/src/agrovision_core/models/
Data pipeline   -> agrovision_core/src/agrovision_core/data/
Experimentation -> notebooks/
API             -> backend/main.py
Config          -> config/config.yaml
```

**Rule of thumb (updated):** ignore `data/raw/`, `data/processed/`, and `outputs/`. Version everything else.
(You can keep empty folders using `.gitkeep` files if you want.)

---

## 2) Divide work across 5 students (balanced, parallel, minimal dependency) â€” **UPDATED (FastAPI + React)**

### Student A â€” Data pipeline (prep + dataset loader)

**Owns:**
`agrovision_core/src/agrovision_core/data/*`, `config/config.yaml`, `data/splits/*`, `data/processed/*` (generated locally)

* Download instructions + folder organization (`data/raw/...`)
* `prepare_dataset.py` to generate:

  * `data/processed/*.npy`
  * `data/processed/class_map.json`
  * optional `data/splits/*.csv`
* `dataset.py` that loads from `data/processed/` (fast, PyTorch-ready)
* Defines/maintains **band list + normalization** in `config.yaml`

**Delivers:**
â€œRun one script â†’ processed data exists â†’ training loads batches correctly.â€

---

### Student B â€” Model implementation (baseline + custom transformer blocks)

**Owns:**
`agrovision_core/src/agrovision_core/models/*`

* Build baseline **U-Net from scratch** (`unet_baseline.py`)
* Implement reusable components (`blocks.py`) including:

  * CNN blocks (Convâ€“BNâ€“ReLU, down/up blocks)
  * **Transformer blocks** (as required by the course)
* Build custom architecture using transformer blocks (`unet_transformer.py`)
* Ensure configurable:

  * `in_channels = C`
  * `num_classes = K`
* Dummy test with shapes:

  * input: `(B, C, 256, 256)`
  * output: `(B, K, 256, 256)`

**Delivers:**
â€œExplains architectural choices + passes dummy tensor test + ready to plug into training.â€

---

### Student C â€” Training + evaluation

**Owns:**
`agrovision_core/src/agrovision_core/train/*`

* Training loop + checkpointing to `outputs/runs/`
* Losses: Cross-Entropy + optional Dice
* Metrics: mIoU, per-class IoU, macro F1
* Evaluation script + metric reports

**Delivers:**
â€œTrain baseline/custom model and produce reproducible metrics + best checkpoint.â€

---

### Student D â€” Backend inference + API (FastAPI)

**Owns:**
`backend/main.py`, `backend/api/*`, `backend/services/*` (and backend-only helpers if needed)

* Build **FastAPI backend**
* API endpoints (example):

  * `POST /api/infer` â†’ returns overlay + stats
  * `GET /api/legend` â†’ class names + colors
  * `POST /api/export` (optional)
* `inference_service.py` bridges API â†’ ML code
* Load trained model once (cached in backend)
* Import shared ML code from `agrovision_core` (models/utils/train artifacts)

**Delivers:**
â€œFrontend can call backend API and receive overlay + stats reliably.â€

---

### Student E â€” Frontend (React + shadcn)

**Owns:**
`frontend/src/*`

* React UI using **shadcn components**
* Map-like AOI selection concept
* â€œRun Analysisâ€ button â†’ calls `POST /api/infer`
* Opacity slider, legend, stats table
* Export buttons (PNG + CSV via backend)
* UX states: loading, disabled (tile limit), errors

**Delivers:**
â€œWorking frontend that consumes backend API and displays/exports results.â€

---

## 3) Maximize parallel work (dependency map + how to avoid blocking)

### Minimal dependency chain

* **A (Data)** and **B (Model)** start immediately in parallel.
* **C (Training)** can start with **synthetic/dummy data** before A finishes.
* **D (Backend)** can start with **mock inference outputs** before training finishes.
* **E (Frontend)** can start with **mock API responses** before backend is complete.

â¡ï¸ No student waits for another.

### Practical â€œmock-firstâ€ approach (so nobody blocks)

* Define a **shared API contract early**:

  ```text
  POST /api/infer
  â†’ overlay_image (base64 or URL)
  â†’ stats_table (JSON)
  â†’ raw_mask (optional)
  ```

* Student D implements mock API responses first

* Student E builds UI against mock API

* When Student C produces `best_model.pth`, Student D switches mock â†’ real inference

### Weekly-style parallel milestones

* **Milestone 1:**
  Dataset prep works + model runs on dummy input + frontend UI renders mock results
* **Milestone 2:**
  Training produces checkpoint + backend uses real model + frontend fully wired
* **Milestone 3:**
  Evaluation report + exports + README + demo polish

### One-line team rule (recommended to include)

> **Backend owns API. Frontend owns UI. Shared ML lives in `agrovision_core`.
> Communication happens only through API calls.
> Training is offline and never triggered from the frontend.**

---

## 4) Where is the access for the app? (Entry points)

### âœ… Two entry points (Frontend + Backend)

### Backend (FastAPI)

```
backend/main.py
```

This is the **only Python file that is run**.

**Example (recommended with uv):**

```bash
uv run uvicorn backend.main:app --reload
```

The backend:

* loads the trained model (checkpoint produced by training)
* runs inference
* exposes REST APIs for the frontend

---

### Frontend (React + shadcn)

```
frontend/src/main.tsx
```

**Example:**

```bash
cd frontend
npm install
npm run dev
```

â¡ï¸ The frontend **never runs ML code**.
â¡ï¸ It only communicates with the backend via HTTP APIs.

---

## 5) How the project is split across students (very important)

> **Key rule:**
> Each student owns **one folder** (shared ML library, backend API, or frontend).
> ML code lives in `agrovision_core` and is **imported**, not duplicated.

### Folder ownership

```
agrovision_core/src/agrovision_core/
â”œâ”€ data/        â†’ Student A (data pipeline)
â”œâ”€ models/      â†’ Student B (model architecture)
â”œâ”€ train/       â†’ Student C (training & evaluation)
â””â”€ utils/       â†’ shared helpers

backend/
â”œâ”€ api/         â†’ Student D (FastAPI routes)
â”œâ”€ services/    â†’ Student D (connect API to ML)
â””â”€ main.py      â†’ backend entry point

frontend/
â””â”€ src/         â†’ Student E (React + shadcn UI)
```

### What this means in practice

* Students **do not edit each otherâ€™s folders**
* ML code is reused by importing it into FastAPI from `agrovision_core`
* Frontend and backend work **independently**
* Integration happens via **API contracts**, not shared files

---

## 6) High-level connection (one-page mental model)

```
User
 â†“
Frontend (React + shadcn)
 â†“   HTTP (JSON)
Backend (FastAPI)
 â†“
ML library (agrovision_core)
 â†“
Model + Stats + Overlay
 â†“
Backend returns JSON + image
 â†“
Frontend displays + exports
```

Or in folders:

```
frontend/
   â†“ (API calls)
backend/
   â”œâ”€ api/
   â””â”€ services/
         â†“ (imports)
agrovision_core/
   â”œâ”€ models/
   â”œâ”€ train/       (offline)
   â”œâ”€ data/        (offline)
   â””â”€ utils/
```

Training is **separate and offline**:

```
agrovision_core/train/ â†’ agrovision_core/models/
agrovision_core/train/ â†’ agrovision_core/data/
```

---

## 7) Detailed connection: who calls whom (important)

## A) Frontend (React) â€” Student E

**Role:**

* UI only (map selection, buttons, sliders, tables)
* No ML logic
* No direct access to model or data

**What it does:**

1. User selects region (AOI)
2. User clicks **Run Analysis**
3. Sends request to backend API (`POST /api/infer`)
4. Receives:

   * overlay image (URL or base64)
   * stats table (JSON)
5. Displays results + export options

---

## B) Backend (FastAPI) â€” Student D

### `backend/api/routes.py`

**Role:** define REST endpoints

Examples:

* `POST /api/infer`
* `GET /api/legend`
* `POST /api/export`

### `backend/services/inference_service.py`

**Role:** bridge between API and ML code

Example import style:

```python
from agrovision_core.models.unet_baseline import UNet
from agrovision_core.utils.io import load_config
```

* Loads trained model once (cached)
* Calls shared ML functions / model code
* Formats results for API response

---

## C) `models/` (pure deep learning) â€” Student B

### `unet_baseline.py / unet_transformer.py`

* ONLY PyTorch code
* No file I/O
* No API or UI logic
* Built from scratch (baseline + transformer blocks)

Used by:

* `agrovision_core/train/train.py`
* backend inference service (runtime)

---

## D) `train/` (offline, not part of runtime) â€” Student C

### `train.py`

**Uses:**

```python
from agrovision_core.data.dataset import CropDataset
from agrovision_core.models.unet_baseline import UNet
```

**Produces:**

```
outputs/runs/best_model.pth
```

â¡ï¸ The backend **loads this file**.
â¡ï¸ Training is never triggered from the frontend.

---

## E) `data/` (used only by training) â€” Student A

### `prepare_dataset.py`

* Converts raw TIFFs â†’ `.npy`
* Creates `data/processed/`

### `dataset.py`

* PyTorch `Dataset`
* Loads from `data/processed/`

â¡ï¸ Neither backend APIs nor frontend touch raw data.

---

## F) `config/config.yaml` (glue)

Used by:

* training
* backend inference

Contains:

```yaml
model_path: outputs/runs/best_model.pth
tile_limit: 9
class_names: [...]
class_colors: [...]
device: cuda
```

â¡ï¸ Change behavior without touching frontend or backend logic.

---

## 8) One full execution trace (step-by-step)

### User runs (two terminals)

**Backend (recommended via uv)**

```bash
uv run uvicorn backend.main:app --reload
```

**Frontend**

```bash
cd frontend
npm install
npm run dev
```

### Runtime flow

1. Frontend loads UI
2. User selects AOI
3. User clicks **Run Analysis**
4. Frontend sends request to backend (`POST /api/infer`)
5. Backend loads model once (cached)
6. Backend runs inference + stats
7. Backend returns JSON + overlay image
8. Frontend renders overlay, stats, and export buttons

---

## 9) Why this structure is correct (and safe for grading)

* **Clear frontend/backend separation**
* **Industry-standard architecture**
* **No ML code in the frontend**
* **No UI code in the ML layer**
* **Clear ownership per student**
* **Easy to mock APIs**
* **Scales to real deployment**
* **Notebooks stay clean** (imports work because shared ML is packaged as `agrovision_core`)
