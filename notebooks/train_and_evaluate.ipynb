{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AgroVision Training and Evaluation\n",
        "\n",
        "This notebook imports the ML library from `backend/src` and runs training/evaluation.\n",
        "Do not execute `train.py` as a script from notebooks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73bc53c4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "os.chdir(Path.cwd().parent)\n",
        "print(\"Working directory is now:\", Path.cwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "251482f6",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from src.train.train import train\n",
        "from src.train.evaluate import evaluate\n",
        "from src.utils.io import load_config\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b8e6472",
      "metadata": {},
      "outputs": [],
      "source": [
        "cfg = load_config(\"config/config.yaml\")\n",
        "\n",
        "training_cfg = cfg.setdefault(\"training\", {})\n",
        "training_cfg.setdefault(\"ignore_index\", 0)\n",
        "training_cfg.setdefault(\"min_labeled_fraction\", 0.05)\n",
        "\n",
        "# Optional: avoid Windows/Jupyter multiprocessing issues\n",
        "# training_cfg[\"num_workers\"] = 0\n",
        "\n",
        "model, train_metrics = train(cfg)\n",
        "eval_results = evaluate(model, cfg)\n",
        "train_metrics, eval_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d0e9500",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Checks: class distribution, label mapping, and predictions\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from src.data.dataset import CropDataset\n",
        "from src.utils.io import resolve_path\n",
        "\n",
        "if \"cfg\" not in globals():\n",
        "    raise RuntimeError(\"Run the config cell first.\")\n",
        "if \"model\" not in globals():\n",
        "    raise RuntimeError(\"Run the training cell first.\")\n",
        "\n",
        "processed_dir = resolve_path(cfg[\"paths\"][\"data_processed\"])\n",
        "masks_path = processed_dir / \"val_masks.npy\"\n",
        "if not masks_path.exists():\n",
        "    raise FileNotFoundError(f\"Missing {masks_path}\")\n",
        "\n",
        "masks = np.load(masks_path, mmap_mode=\"r\")\n",
        "print(\"val_masks.npy shape:\", masks.shape, \"dtype:\", masks.dtype)\n",
        "\n",
        "# Class distribution from raw mask ids\n",
        "counts = {}\n",
        "chunk_size = 32\n",
        "for start in range(0, masks.shape[0], chunk_size):\n",
        "    chunk = masks[start:start + chunk_size]\n",
        "    vals, cts = np.unique(chunk, return_counts=True)\n",
        "    for v, c in zip(vals.tolist(), cts.tolist()):\n",
        "        counts[int(v)] = counts.get(int(v), 0) + int(c)\n",
        "\n",
        "total_pixels = sum(counts.values())\n",
        "sorted_counts = sorted(counts.items(), key=lambda x: x[0])\n",
        "print(\"Unique raw class ids in masks:\", [k for k, _ in sorted_counts])\n",
        "print(\"Background pixel ratio:\", counts.get(0, 0) / total_pixels if total_pixels else 0.0)\n",
        "\n",
        "cfg_class_ids = sorted(int(k) for k in cfg.get(\"classes\", {}).keys())\n",
        "extra = [cid for cid, _ in sorted_counts if cid not in cfg_class_ids]\n",
        "missing = [cid for cid in cfg_class_ids if cid not in counts]\n",
        "print(\"Extra ids not in cfg:\", extra)\n",
        "print(\"Missing ids not in masks:\", missing)\n",
        "\n",
        "print(\"Top classes by pixel count:\")\n",
        "for cid, cnt in sorted(counts.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "    name = cfg.get(\"classes\", {}).get(cid, {}).get(\"name\", \"Unknown\")\n",
        "    print(f\"  {cid} ({name}): {cnt} pixels ({cnt/total_pixels:.4%})\")\n",
        "\n",
        "val_dataset = CropDataset(\"val\", cfg)\n",
        "contig_ids = sorted(val_dataset.class_map.values())\n",
        "if contig_ids != list(range(len(contig_ids))):\n",
        "    print(\"Warning: non-contiguous class_map values:\", contig_ids)\n",
        "\n",
        "device = next(model.parameters()).device\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
        "batch = next(iter(val_loader))\n",
        "images = batch[\"image\"].to(device)\n",
        "gt_masks = batch[\"mask\"].cpu().numpy()\n",
        "\n",
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "    logits = model(images)\n",
        "pred_masks = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "\n",
        "# Build color map from cfg (raw ids)\n",
        "color_map = {}\n",
        "for raw_id, info in cfg.get(\"classes\", {}).items():\n",
        "    try:\n",
        "        color_map[int(raw_id)] = info.get(\"color\", [0, 0, 0])\n",
        "    except (TypeError, ValueError):\n",
        "        pass\n",
        "\n",
        "index_to_raw = val_dataset.index_to_raw\n",
        "ignore_index = int(cfg.get(\"training\", {}).get(\"ignore_index\", 0))\n",
        "\n",
        "def _mask_to_rgb(mask_contig):\n",
        "    h, w = mask_contig.shape\n",
        "    rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "    for contig_id, raw_id in index_to_raw.items():\n",
        "        color = color_map.get(int(raw_id), [0, 0, 0])\n",
        "        rgb[mask_contig == contig_id] = color\n",
        "    rgb[mask_contig == ignore_index] = [255, 255, 255]\n",
        "    return rgb\n",
        "\n",
        "band_names = [b.get(\"name\") for b in cfg.get(\"bands\", [])]\n",
        "band_idx = {name: i for i, name in enumerate(band_names) if name}\n",
        "rgb_indices = [band_idx[name] for name in (\"B04\", \"B03\", \"B02\") if name in band_idx]\n",
        "if len(rgb_indices) != 3:\n",
        "    rgb_indices = [0, 1, 2]\n",
        "\n",
        "def _to_rgb(image_tensor):\n",
        "    arr = image_tensor.detach().cpu().numpy()\n",
        "    rgb = arr[rgb_indices, :, :]\n",
        "    rgb = np.stack(rgb, axis=-1)\n",
        "    min_val = rgb.min(axis=(0, 1), keepdims=True)\n",
        "    max_val = rgb.max(axis=(0, 1), keepdims=True)\n",
        "    rgb = (rgb - min_val) / np.clip(max_val - min_val, 1e-6, None)\n",
        "    return rgb\n",
        "\n",
        "n = min(4, images.shape[0])\n",
        "fig, axes = plt.subplots(n, 3, figsize=(12, 4 * n))\n",
        "if n == 1:\n",
        "    axes = np.expand_dims(axes, axis=0)\n",
        "\n",
        "for i in range(n):\n",
        "    axes[i, 0].imshow(_to_rgb(images[i]))\n",
        "    axes[i, 0].set_title(\"Image\")\n",
        "    axes[i, 1].imshow(_mask_to_rgb(gt_masks[i]))\n",
        "    axes[i, 1].set_title(\"GT mask\")\n",
        "    axes[i, 2].imshow(_mask_to_rgb(pred_masks[i]))\n",
        "    axes[i, 2].set_title(\"Pred mask\")\n",
        "    for j in range(3):\n",
        "        axes[i, j].axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f3bfb47",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick visualization of one validation tile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "from src.data.dataset import CropDataset\n",
        "\n",
        "if \"cfg\" not in globals() or \"model\" not in globals():\n",
        "    raise RuntimeError(\"Run the training cell first.\")\n",
        "\n",
        "val_dataset = CropDataset(\"val\", cfg)\n",
        "device = next(model.parameters()).device\n",
        "sample = val_dataset[0]\n",
        "image = sample[\"image\"]\n",
        "mask = sample[\"mask\"].cpu().numpy()\n",
        "\n",
        "ignore_index = int(cfg.get(\"training\", {}).get(\"ignore_index\", 0))\n",
        "\n",
        "with torch.inference_mode():\n",
        "    pred_logits = model(image.unsqueeze(0).to(device))\n",
        "pred_mask = torch.argmax(pred_logits, dim=1).squeeze(0).cpu().numpy()\n",
        "\n",
        "color_map = {}\n",
        "for raw_id, info in cfg.get(\"classes\", {}).items():\n",
        "    try:\n",
        "        color_map[int(raw_id)] = info.get(\"color\", [0, 0, 0])\n",
        "    except (TypeError, ValueError):\n",
        "        pass\n",
        "\n",
        "index_to_raw = val_dataset.index_to_raw\n",
        "\n",
        "def _mask_to_rgb_quick(mask_contig):\n",
        "    h, w = mask_contig.shape\n",
        "    rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
        "    for contig_id, raw_id in index_to_raw.items():\n",
        "        rgb[mask_contig == contig_id] = color_map.get(int(raw_id), [0, 0, 0])\n",
        "    rgb[mask_contig == ignore_index] = [255, 255, 255]\n",
        "    return rgb\n",
        "\n",
        "band_names = [b.get(\"name\") for b in cfg.get(\"bands\", [])]\n",
        "band_idx = {name: i for i, name in enumerate(band_names) if name}\n",
        "rgb_indices = [band_idx[name] for name in (\"B04\", \"B03\", \"B02\") if name in band_idx]\n",
        "if len(rgb_indices) != 3:\n",
        "    rgb_indices = [0, 1, 2]\n",
        "\n",
        "def _to_rgb_quick(image_tensor):\n",
        "    arr = image_tensor.cpu().numpy()\n",
        "    rgb = arr[rgb_indices, :, :]\n",
        "    rgb = np.stack(rgb, axis=-1)\n",
        "    min_val = rgb.min(axis=(0, 1), keepdims=True)\n",
        "    max_val = rgb.max(axis=(0, 1), keepdims=True)\n",
        "    rgb = (rgb - min_val) / np.clip(max_val - min_val, 1e-6, None)\n",
        "    return rgb\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "axes[0].imshow(_to_rgb_quick(image))\n",
        "axes[0].set_title(\"Image\")\n",
        "axes[1].imshow(_mask_to_rgb_quick(mask))\n",
        "axes[1].set_title(\"GT\")\n",
        "axes[2].imshow(_mask_to_rgb_quick(pred_mask))\n",
        "axes[2].set_title(\"Prediction\")\n",
        "for ax in axes:\n",
        "    ax.axis(\"off\")\n",
        "plt.tight_layout()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
